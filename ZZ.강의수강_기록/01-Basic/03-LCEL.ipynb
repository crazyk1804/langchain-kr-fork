{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b style=\"color:rgb(247, 118, 167)\">LCEL</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from ck_helper import print_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      " [name]\n",
      " None\n",
      "========================================\n",
      " [input_variables]\n",
      " ['something']\n",
      "========================================\n",
      " [optional_variables]\n",
      " []\n",
      "========================================\n",
      " [input_types]\n",
      " {}\n",
      "========================================\n",
      " [output_parser]\n",
      " None\n",
      "========================================\n",
      " [partial_variables]\n",
      " {}\n",
      "========================================\n",
      " [metadata]\n",
      " None\n",
      "========================================\n",
      " [tags]\n",
      " None\n",
      "========================================\n",
      " [template]\n",
      " {something}은 뭐가 좋을까?\n",
      "========================================\n",
      " [template_format]\n",
      " f-string\n",
      "========================================\n",
      " [validate_template]\n",
      " False\n"
     ]
    }
   ],
   "source": [
    "template = '{something}은 뭐가 좋을까?'\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "print_attrs(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: <class 'str'>, value: 오늘 점심은 뭐가 좋을까?\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(something = '오늘 점심')\n",
    "print(f'type: {type(prompt)}, value: {prompt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model_name = 'gpt-4o-mini'\n",
    "llm = ChatOpenAI(temperature=.3, model_name=model_name, max_tokens=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | llm\n",
    "response = chain.invoke({'something': '오늘 점심'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'오늘 점심으로는 어떤 음식을 드시고 싶으신가요? 한식, 중식, 일식, 양식 등 다양한 선택지가 있습니다. 예를 들어, 비빔밥이나 김치찌개 같은 한식, 또는 초밥이나 라멘 같은 일식도 좋고, 파스타나 샌드위치 같은 양식도 괜찮습니다. 기분이나 날씨에 따라 선택해 보세요!'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "점심 메뉴로 몇 가지 추천해드릴게요!\n",
      "\n",
      "1. **비빔밥** - 다양한 채소와 고기를 섞어 먹는 건강한 한 그릇 요리입니다.\n",
      "2. **김치찌개** - 따뜻하고 얼큰한 국물 요리로, 밥과 함께 먹으면 좋습니다.\n",
      "3. **쌈밥** - 상추나 배추에 고기와 밥을 싸서 먹는 상큼한 메뉴입니다.\n",
      "4. **파스타** - 크림 소스나 토마토 소스의 파스타도 간편하면서 맛있습니다.\n",
      "5. **샐러드** - 가벼운 점심을\n"
     ]
    }
   ],
   "source": [
    "output_parser = StrOutputParser()\n",
    "chain = chain | output_parser\n",
    "response = chain.invoke({'something': '오늘 점심'})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **템플릿 변경**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''\n",
    "너는 영어선생이야. [format]에 맞춰 영어회화를 작성해줘.\n",
    "상황: {situation}\n",
    "[format]\n",
    "- 영어:\n",
    "- 해석:\n",
    "'''\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어: \"I can't believe I walked around with my zipper down while wearing red underwear! What was I thinking?\"\n",
      "- 해석: \"빨간 속옷을 입고 지퍼를 열고 다니면서 내가 뭘 생각하고 있었는지 믿을 수가 없어!\""
     ]
    }
   ],
   "source": [
    "answer = chain.stream({'situation': '빨간 속옷을 입고 지퍼를 열고 다녔어'})\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CVAL\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "logging.langsmith('CVAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from ck_helper import print_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = '{country}의 수도는 어디인가'\n",
    "prompt_template = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      " [name]\n",
      " None\n",
      "========================================\n",
      " [input_variables]\n",
      " ['country']\n",
      "========================================\n",
      " [optional_variables]\n",
      " []\n",
      "========================================\n",
      " [input_types]\n",
      " {}\n",
      "========================================\n",
      " [output_parser]\n",
      " None\n",
      "========================================\n",
      " [partial_variables]\n",
      " {}\n",
      "========================================\n",
      " [metadata]\n",
      " None\n",
      "========================================\n",
      " [tags]\n",
      " None\n",
      "========================================\n",
      " [template]\n",
      " {country}의 수도는 어디인가\n",
      "========================================\n",
      " [template_format]\n",
      " f-string\n",
      "========================================\n",
      " [validate_template]\n",
      " False\n"
     ]
    }
   ],
   "source": [
    "print_attrs(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마닐라의 수도는 어디인가\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt_template.format(country='마닐라')\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4o-mini',\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='{country}의 수도는 어디인가') middle=[] last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7ff7f4132c50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7ff7e6c0d090>, root_client=<openai.OpenAI object at 0x7ff7e6f0c0d0>, root_async_client=<openai.AsyncOpenAI object at 0x7ff7f419c090>, model_name='gpt-4o-mini', temperature=0.1, model_kwargs={}, openai_api_key=SecretStr('**********'))\n"
     ]
    }
   ],
   "source": [
    "chain = prompt_template | llm\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {'country': '마닐라'}\n",
    "response = chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      " [content]\n",
      " 마닐라는 필리핀의 수도입니다. 마닐라는 필리핀의 정치, 경제, 문화의 중심지로, 다양한 역사적 유적과 현대적인 시설이 공존하는 도시입니다.\n",
      "========================================\n",
      " [additional_kwargs]\n",
      " {'refusal': None}\n",
      "========================================\n",
      " [response_metadata]\n",
      " {'token_usage': {'completion_tokens': 46, 'prompt_tokens': 16, 'total_tokens': 62, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}\n",
      "========================================\n",
      " [type]\n",
      " ai\n",
      "========================================\n",
      " [name]\n",
      " None\n",
      "========================================\n",
      " [id]\n",
      " run-78140873-b735-4729-b5ac-86eebb9f87d0-0\n",
      "========================================\n",
      " [example]\n",
      " False\n",
      "========================================\n",
      " [tool_calls]\n",
      " []\n",
      "========================================\n",
      " [invalid_tool_calls]\n",
      " []\n",
      "========================================\n",
      " [usage_metadata]\n",
      " {'input_tokens': 16, 'output_tokens': 46, 'total_tokens': 62, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print_attrs(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마닐라는 필리핀의 수도입니다. 필리핀의 정치, 경제, 문화의 중심지로 알려져 있습니다."
     ]
    }
   ],
   "source": [
    "answer = chain.stream(input)\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **OutputParser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      " [name]\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "print_attrs(output_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chain | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "마닐라는 필리핀의 수도입니다. 필리핀의 정치, 경제, 문화의 중심지로 알려져 있습니다.\n"
     ]
    }
   ],
   "source": [
    "answer = chain.invoke({'country': '마닐라'})\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''\n",
    "너는 인공지능 전문가야.\n",
    "내 말에는 무조건 복종하지.\n",
    "상황에 맞는 답변을 작성하여라.\n",
    "\n",
    "# 상황\n",
    "{question}\n",
    "\n",
    "# FORMAT\n",
    " - 모델:\n",
    " - 사용예시:\n",
    "'''\n",
    " \n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "model = ChatOpenAI(model_name='gpt-4o-mini')\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt_template | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = chain.invoke({'question': '제조 공장에서 이상탐지를 하고싶어. 해결책은?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 모델: 이상 탐지 모델 (예: LSTM, Autoencoder, Isolation Forest 등)\n",
      "- 사용예시: 제조 공장에서 센서 데이터를 수집하여, LSTM 모델을 훈련시켜 정상적인 패턴을 학습합니다. 이후 실시간으로 새로운 데이터가 들어올 때마다 모델이 이를 분석하여 이상 징후를 탐지하고, 예를 들어 특정 기계의 온도가 비정상적으로 상승하면 이를 경고하는 시스템을 구현할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
